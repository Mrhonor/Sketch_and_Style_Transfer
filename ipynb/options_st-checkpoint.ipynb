{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "\n",
    "class TrainOptions():\n",
    "    def __init__(self):\n",
    "        self.parser = argparse.ArgumentParser()\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self):\n",
    "        self.parser.add_argument('--exp_name', type=str, default=\"Exp0\", help='the name of experiment')\n",
    "        self.parser.add_argument('--epoch_start', type=int, default=0, help='epoch to start training from')\n",
    "        self.parser.add_argument('--epoch_num', type=int, default=200, help='number of epochs of training')\n",
    "        self.parser.add_argument('--data_root', type=str, default=\"../../data\", help='directory of the dataset')\n",
    "        self.parser.add_argument('--dataset_name', type=str, default=\"maps\", help='name of the dataset')\n",
    "        self.parser.add_argument('--batch_size', type=int, default=1, help='size of the batches')\n",
    "        self.parser.add_argument('--lr', type=float, default=0.0002, help='adam: learning rate')\n",
    "        self.parser.add_argument('--b1', type=float, default=0.5, help='adam: decay of first order momentum of gradient')\n",
    "        self.parser.add_argument('--b2', type=float, default=0.999, help='adam: decay of first order momentum of gradient')\n",
    "        self.parser.add_argument('--decay_epoch', type=int, default=100, help='epoch from which to start lr decay')\n",
    "        self.parser.add_argument('--n_cpu', type=int, default=8, help='number of cpu threads to use during batch generation')\n",
    "        self.parser.add_argument('--img_height', type=int, default=256, help='size of image height')\n",
    "        self.parser.add_argument('--img_width', type=int, default=256, help='size of image width')\n",
    "        self.parser.add_argument('--input_nc_A', type=int, default=3, help='# of input image channels for G_AB')\n",
    "        self.parser.add_argument('--input_nc_B', type=int, default=3, help='# of output image channels for G_BA')\n",
    "        self.parser.add_argument('--sample_interval', type=int, default=200, help='interval between sampling of images from generators')\n",
    "        self.parser.add_argument('--checkpoint_interval', type=int, default=-1, help='interval between model checkpoints')\n",
    "        self.parser.add_argument('--n_residual_blocks', type=int, default=9, help='number of residual blocks in generator')\n",
    "        self.parser.add_argument('--n_D_layers', type=int, default=4, help='used to decision the patch_size in D-net, should less than 8')\n",
    "        self.parser.add_argument('--lambda_cyc', type=int, default=10, help=' -------------------------------------------')\n",
    "        self.parser.add_argument('--lambda_id', type=float, default=0.5,\n",
    "                                 help='use identity mapping. Setting lambda_identity other than 0 has an effect of scaling the weight of the identity mapping loss.'\n",
    "                                 'For example, if the weight of the identity loss should be 10 times smaller than the weight of the reconstruction loss, please set lambda_identity = 0.1')\n",
    "        self.parser.add_argument('--pool_size', type=int, default=50, help='the size of image buffer that stores previously generated images')\n",
    "        self.parser.add_argument('--img_result_dir', type=str, default='result_images', help=' where to save the result images')\n",
    "        self.parser.add_argument('--model_result_dir', type=str, default='saved_models', help=' where to save the checkpoints')\n",
    "\n",
    "\n",
    "    def parse(self):\n",
    "        if not self.initialized:\n",
    "            self.initialize()\n",
    "        args = self.parser.parse_args()\n",
    "\n",
    "        os.makedirs('%s-%s/%s' % (args.exp_name, args.dataset_name, args.img_result_dir), exist_ok=True)\n",
    "        os.makedirs('%s-%s/%s' % (args.exp_name, args.dataset_name, args.model_result_dir), exist_ok=True)\n",
    "\n",
    "        print('------------ Options -------------')\n",
    "        with open(\"./%s-%s/args.log\" % (args.exp_name,  args.dataset_name) ,\"w\") as args_log:\n",
    "            for k, v in sorted(vars(args).items()):\n",
    "                print('%s: %s ' % (str(k), str(v)))\n",
    "                args_log.write('%s: %s \\n' % (str(k), str(v)))\n",
    "\n",
    "        print('-------------- End ----------------')\n",
    "\n",
    "        self.args = args\n",
    "        return self.args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
